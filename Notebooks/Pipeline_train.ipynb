{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import shap\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "import joblib\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Preprocess data\n",
    "train = pd.read_csv(\"C:/Users/willi/Python/Spotify_Project/Data/final_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>popularity</th>\n",
       "      <th>genres</th>\n",
       "      <th>sub-genres</th>\n",
       "      <th>explicit</th>\n",
       "      <th>followers</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>73</td>\n",
       "      <td>69</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>9012980</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.890</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>139.986</td>\n",
       "      <td>201400</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>76</td>\n",
       "      <td>69</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>3152834</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.578</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.970</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94.514</td>\n",
       "      <td>256733</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81</td>\n",
       "      <td>54</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>20164612</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.696</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.572</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93.034</td>\n",
       "      <td>207627</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>81</td>\n",
       "      <td>24</td>\n",
       "      <td>121</td>\n",
       "      <td>0</td>\n",
       "      <td>55382107</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.640</td>\n",
       "      <td>7</td>\n",
       "      <td>-8.415</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.019</td>\n",
       "      <td>246960</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>84</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>11245845</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.574</td>\n",
       "      <td>11</td>\n",
       "      <td>-7.961</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>125.173</td>\n",
       "      <td>209107</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   popularity  genres  sub-genres  explicit  followers  danceability  energy   \n",
       "0          73      69         121         0    9012980         0.837   0.462  \\\n",
       "1          76      69         138         0    3152834         0.656   0.578   \n",
       "2          81      54          67         1   20164612         0.629   0.696   \n",
       "3          81      24         121         0   55382107         0.779   0.640   \n",
       "4          82      84          59         1   11245845         0.614   0.574   \n",
       "\n",
       "   key  loudness  mode  instrumentalness  liveness    tempo  duration_ms   \n",
       "0    0    -7.890     1                 0         0  139.986       201400  \\\n",
       "1    7    -8.970     0                 0         0   94.514       256733   \n",
       "2    1    -5.572     0                 0         0   93.034       207627   \n",
       "3    7    -8.415     1                 0         0   99.019       246960   \n",
       "4   11    -7.961     1                 0         0  125.173       209107   \n",
       "\n",
       "   time_signature  mood  \n",
       "0               4     1  \n",
       "1               4     1  \n",
       "2               4     1  \n",
       "3               4     0  \n",
       "4               5     1  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n"
     ]
    }
   ],
   "source": [
    "print(train['sub-genres'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(\"mood\", axis=1)\n",
    "y = train[\"mood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_TRACKING_URI = os.getenv(\"MLFLOW_TRACKING_URI\")\n",
    "MLFLOW_TRACKING_USERNAME = os.getenv(\"MLFLOW_TRACKING_USERNAME\")\n",
    "MLFLOW_TRACKING_PASSWORD = os.getenv(\"MLFLOW_TRACKING_PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/inouyewilliam/Master-Thesis.mlflow\")\n",
    "    \n",
    "logged_model = 'runs:/5cf7eb61d49d4df4b38bbfa2ed92cd4c/model'\n",
    "loaded_model = mlflow.sklearn.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.0355071248026683, max_depth=3, n_estimators=196,\n",
       "               num_leaves=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.0355071248026683, max_depth=3, n_estimators=196,\n",
       "               num_leaves=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.0355071248026683, max_depth=3, n_estimators=196,\n",
       "               num_leaves=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.best_estimator_.named_steps['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "LightGBMError",
     "evalue": "The number of features in data (15) is not the same as it was in training data (10).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m explainer \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mExplainer(loaded_model\u001b[39m.\u001b[39mbest_estimator_\u001b[39m.\u001b[39mnamed_steps[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m----> 2\u001b[0m shap_values \u001b[39m=\u001b[39m explainer(X)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Visualize SHAP values\u001b[39;00m\n\u001b[0;32m      5\u001b[0m shap\u001b[39m.\u001b[39msummary_plot(shap_values, X)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\shap\\explainers\\_tree.py:217\u001b[0m, in \u001b[0;36mTree.__call__\u001b[1;34m(self, X, y, interactions, check_additivity)\u001b[0m\n\u001b[0;32m    214\u001b[0m     feature_names \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mdata_feature_names\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m interactions:\n\u001b[1;32m--> 217\u001b[0m     v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshap_values(X, y\u001b[39m=\u001b[39;49my, from_call\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, check_additivity\u001b[39m=\u001b[39;49mcheck_additivity, approximate\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapproximate)\n\u001b[0;32m    218\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(v) \u001b[39mis\u001b[39;00m \u001b[39mlist\u001b[39m:\n\u001b[0;32m    219\u001b[0m         v \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mstack(v, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m# put outputs at the end\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\shap\\explainers\\_tree.py:349\u001b[0m, in \u001b[0;36mTree.shap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mlightgbm\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    348\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m approximate, \u001b[39m\"\u001b[39m\u001b[39mapproximate=True is not supported for LightGBM models!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 349\u001b[0m     phi \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49moriginal_model\u001b[39m.\u001b[39;49mpredict(X, num_iteration\u001b[39m=\u001b[39;49mtree_limit, pred_contrib\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    350\u001b[0m     \u001b[39m# Note: the data must be joined on the last axis\u001b[39;00m\n\u001b[0;32m    351\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39moriginal_model\u001b[39m.\u001b[39mparams[\u001b[39m'\u001b[39m\u001b[39mobjective\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\lightgbm\\basic.py:3538\u001b[0m, in \u001b[0;36mBooster.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[0;32m   3536\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3537\u001b[0m         num_iteration \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m-> 3538\u001b[0m \u001b[39mreturn\u001b[39;00m predictor\u001b[39m.\u001b[39;49mpredict(data, start_iteration, num_iteration,\n\u001b[0;32m   3539\u001b[0m                          raw_score, pred_leaf, pred_contrib,\n\u001b[0;32m   3540\u001b[0m                          data_has_header, is_reshape)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\lightgbm\\basic.py:848\u001b[0m, in \u001b[0;36m_InnerPredictor.predict\u001b[1;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[0;32m    846\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__pred_for_csc(data, start_iteration, num_iteration, predict_type)\n\u001b[0;32m    847\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m--> 848\u001b[0m     preds, nrow \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__pred_for_np2d(data, start_iteration, num_iteration, predict_type)\n\u001b[0;32m    849\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, \u001b[39mlist\u001b[39m):\n\u001b[0;32m    850\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\lightgbm\\basic.py:938\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d\u001b[1;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[0;32m    936\u001b[0m     \u001b[39mreturn\u001b[39;00m preds, nrow\n\u001b[0;32m    937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 938\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_predict(mat, start_iteration, num_iteration, predict_type)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\lightgbm\\basic.py:908\u001b[0m, in \u001b[0;36m_InnerPredictor.__pred_for_np2d.<locals>.inner_predict\u001b[1;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[0;32m    906\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length of pre-allocated predict array\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    907\u001b[0m out_num_preds \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int64(\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 908\u001b[0m _safe_call(_LIB\u001b[39m.\u001b[39;49mLGBM_BoosterPredictForMat(\n\u001b[0;32m    909\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhandle,\n\u001b[0;32m    910\u001b[0m     ptr_data,\n\u001b[0;32m    911\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(type_ptr_data),\n\u001b[0;32m    912\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m]),\n\u001b[0;32m    913\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int32(mat\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m]),\n\u001b[0;32m    914\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(C_API_IS_ROW_MAJOR),\n\u001b[0;32m    915\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(predict_type),\n\u001b[0;32m    916\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(start_iteration),\n\u001b[0;32m    917\u001b[0m     ctypes\u001b[39m.\u001b[39;49mc_int(num_iteration),\n\u001b[0;32m    918\u001b[0m     c_str(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpred_parameter),\n\u001b[0;32m    919\u001b[0m     ctypes\u001b[39m.\u001b[39;49mbyref(out_num_preds),\n\u001b[0;32m    920\u001b[0m     preds\u001b[39m.\u001b[39;49mctypes\u001b[39m.\u001b[39;49mdata_as(ctypes\u001b[39m.\u001b[39;49mPOINTER(ctypes\u001b[39m.\u001b[39;49mc_double))))\n\u001b[0;32m    921\u001b[0m \u001b[39mif\u001b[39;00m n_preds \u001b[39m!=\u001b[39m out_num_preds\u001b[39m.\u001b[39mvalue:\n\u001b[0;32m    922\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mWrong length for predict results\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\lightgbm\\basic.py:125\u001b[0m, in \u001b[0;36m_safe_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \n\u001b[0;32m    119\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[39m    The return value from C API calls.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 125\u001b[0m     \u001b[39mraise\u001b[39;00m LightGBMError(_LIB\u001b[39m.\u001b[39mLGBM_GetLastError()\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m))\n",
      "\u001b[1;31mLightGBMError\u001b[0m: The number of features in data (15) is not the same as it was in training data (10).\nYou can set ``predict_disable_shape_check=true`` to discard this error, but please be aware what you are doing."
     ]
    }
   ],
   "source": [
    "explainer = shap.Explainer(loaded_model.best_estimator_.named_steps['model'])\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# Visualize SHAP values\n",
    "shap.summary_plot(shap_values, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, X_test, y_test):\n",
    "    # Evaluate the model using cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Get the model predictions and probabilities\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    avg_precision= average_precision_score(y_test, y_proba)\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    precision= precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "    f1= f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Return a dictionary of evaluation metrics\n",
    "    return {\n",
    "        \"cv_score\": cv_score,\n",
    "        \"roc_auc\": roc_auc,\n",
    "        \"average_precision\": avg_precision,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-08 22:11:40,031]\u001b[0m A new study created in memory with name: no-name-e6fd96be-fc38-4c8e-8ce2-8992ebb29d3e\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"num_leaves\" } are not used.\n",
      "\n",
      "[22:11:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"num_leaves\" } are not used.\n",
      "\n",
      "[22:11:41] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"num_leaves\" } are not used.\n",
      "\n",
      "[22:11:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"num_leaves\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-05-08 22:11:42,253]\u001b[0m Trial 0 failed with parameters: {'k': 11, 'et_n_estimators': 121, 'et_max_depth': 10, 'lgbm_max_depth': 5, 'lgbm_n_estimators': 90, 'lgbm_num_leaves': 19, 'xgb_max_depth': 7, 'xgb_n_estimators': 79, 'xgb_num_leaves': 45} because of the following error: KeyError('et').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\willi\\AppData\\Local\\Temp\\ipykernel_7308\\3625654654.py\", line 49, in objective\n",
      "    best_pipeline = best_pipelines[best_algo][\"pipeline\"]\n",
      "                    ~~~~~~~~~~~~~~^^^^^^^^^^^\n",
      "KeyError: 'et'\n",
      "\u001b[33m[W 2023-05-08 22:11:42,256]\u001b[0m Trial 0 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:11:42] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"num_leaves\" } are not used.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'et'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39mstart_run():\n\u001b[0;32m     76\u001b[0m     \u001b[39m# Optimize the hyperparameters using Optuna\u001b[39;00m\n\u001b[0;32m     77\u001b[0m     study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mmaximize\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m     study\u001b[39m.\u001b[39;49moptimize(objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m)\n\u001b[0;32m     80\u001b[0m     \u001b[39m# Get the best hyperparameters and score\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     best_params \u001b[39m=\u001b[39m study\u001b[39m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\optuna\\study\\study.py:425\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    322\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    323\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    330\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    332\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \n\u001b[0;32m    334\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    422\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    423\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 425\u001b[0m     _optimize(\n\u001b[0;32m    426\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    427\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    428\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    429\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    430\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    431\u001b[0m         catch\u001b[39m=\u001b[39;49m\u001b[39mtuple\u001b[39;49m(catch) \u001b[39mif\u001b[39;49;00m \u001b[39misinstance\u001b[39;49m(catch, Iterable) \u001b[39melse\u001b[39;49;00m (catch,),\n\u001b[0;32m    432\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    433\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    434\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    435\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\optuna\\study\\_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    164\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    168\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    169\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\optuna\\study\\_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    244\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    246\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    247\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    248\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    249\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    250\u001b[0m ):\n\u001b[1;32m--> 251\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    252\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\willi\\anaconda3\\envs\\mlops\\Lib\\site-packages\\optuna\\study\\_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    199\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 200\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    201\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    202\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    203\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[33], line 49\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m# Choose the best algorithm based on the cross-validation scores\u001b[39;00m\n\u001b[0;32m     48\u001b[0m     best_algo \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(scores, key\u001b[39m=\u001b[39mscores\u001b[39m.\u001b[39mget)\n\u001b[1;32m---> 49\u001b[0m     best_pipeline \u001b[39m=\u001b[39m best_pipelines[best_algo][\u001b[39m\"\u001b[39m\u001b[39mpipeline\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     50\u001b[0m     best_params \u001b[39m=\u001b[39m {\n\u001b[0;32m     51\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mk\u001b[39m\u001b[39m\"\u001b[39m: k,\n\u001b[0;32m     52\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbest_algo\u001b[39m}\u001b[39;00m\u001b[39m_best_params\u001b[39m\u001b[39m\"\u001b[39m: best_pipeline\u001b[39m.\u001b[39mnamed_steps[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mget_params(),\n\u001b[0;32m     53\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mbest_algo\u001b[39m}\u001b[39;00m\u001b[39m_mean_cv_score\u001b[39m\u001b[39m\"\u001b[39m: scores[best_algo],\n\u001b[0;32m     54\u001b[0m                     }\n\u001b[0;32m     55\u001b[0m     \u001b[39m# Save the best pipeline for each algorithm in MLflow\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'et'"
     ]
    }
   ],
   "source": [
    "# Define the objective function to be optimized by Optuna\n",
    "def objective(trial):\n",
    "    k = trial.suggest_int(\"k\", 5, X.shape[1])\n",
    "\n",
    "    # Define the pipelines with different algorithms\n",
    "    pipelines = {\n",
    "        \"et\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k=k)),\n",
    "            (\"model\", ExtraTreesClassifier(\n",
    "                n_estimators=trial.suggest_int(\"et_n_estimators\", 50, 200),\n",
    "                max_depth=trial.suggest_int(\"et_max_depth\", 5, 20),\n",
    "            )),\n",
    "        ]),\n",
    "        \"lgbm\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k=k)),\n",
    "            (\"model\", LGBMClassifier(\n",
    "                #learning_rate=trial.suggest_loguniform(\"lgbm_learning_rate\", 1e-3, 1e-1),\n",
    "                max_depth=trial.suggest_int(\"lgbm_max_depth\", 3, 10),\n",
    "                n_estimators=trial.suggest_int(\"lgbm_n_estimators\", 50, 200),\n",
    "                num_leaves=trial.suggest_int(\"lgbm_num_leaves\", 2, 50),\n",
    "            )),\n",
    "        ]),\n",
    "        \"xgb\": Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k=k)),\n",
    "            (\"model\", XGBClassifier(\n",
    "                #learning_rate=trial.suggest_loguniform(\"xgb_learning_rate\", 1e-3, 1e-1),\n",
    "                max_depth=trial.suggest_int(\"xgb_max_depth\", 3, 10),\n",
    "                n_estimators=trial.suggest_int(\"xgb_n_estimators\", 50, 200),\n",
    "                num_leaves=trial.suggest_int(\"xgb_num_leaves\", 2, 50),\n",
    "            )),\n",
    "        ]),\n",
    "    }\n",
    " # Train and evaluate each pipeline using cross-validation\n",
    "    scores = {}\n",
    "    best_pipelines = {}\n",
    "    for algo, pipeline in pipelines.items():\n",
    "            score = np.mean(cross_val_score(pipeline, X, y, cv=5))\n",
    "            scores[algo] = score\n",
    "        \n",
    "# Save the best pipeline for each algorithm and their corresponding scores\n",
    "    if algo not in best_pipelines or score > best_pipelines[algo][\"score\"]:\n",
    "        best_pipelines[algo] = {\"pipeline\": pipeline, \"score\": score}\n",
    "    \n",
    "# Choose the best algorithm based on the cross-validation scores\n",
    "    best_algo = max(scores, key=scores.get)\n",
    "    best_pipeline = best_pipelines[best_algo][\"pipeline\"]\n",
    "    best_params = {\n",
    "            \"k\": k,\n",
    "            f\"{best_algo}_best_params\": best_pipeline.named_steps[\"model\"].get_params(),\n",
    "            f\"{best_algo}_mean_cv_score\": scores[best_algo],\n",
    "                    }\n",
    "    # Save the best pipeline for each algorithm in MLflow\n",
    "    best_mean_cv_score = None\n",
    "    with mlflow.start_run(nested=True):\n",
    "        for algo, pipeline_info in best_pipelines.items():\n",
    "            pipeline = pipeline_info[\"pipeline\"]\n",
    "            pipeline_name = f\"{algo}_pipeline\"\n",
    "            mlflow.sklearn.log_model(pipeline, pipeline_name)\n",
    "\n",
    "            # Log the best params and score for this pipeline\n",
    "            if algo == best_algo:\n",
    "                mlflow.log_params(best_params)\n",
    "                mlflow.log_metric(\"mean_cv_score\", scores[best_algo])\n",
    "\n",
    "    # Return the mean cross-validation score of the best algorithm\n",
    "    return best_mean_cv_score\n",
    "\n",
    "# Set up MLflow tracking\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/inouyewilliam/Master-Thesis.mlflow\")\n",
    "\n",
    "# Start a new MLflow run to track the experiment\n",
    "with mlflow.start_run():\n",
    "    # Optimize the hyperparameters using Optuna\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100)\n",
    "\n",
    "    # Get the best hyperparameters and score\n",
    "    best_params = study.best_params\n",
    "    best_score = study.best_value\n",
    "    \n",
    "# Save the best model in MLflow\n",
    "with mlflow.start_run(nested=True):\n",
    "    # Train the best pipeline on the full dataset\n",
    "    best_pipeline = best_pipelines[best_algo][\"pipeline\"]\n",
    "    best_pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    cv_score,roc_auc,average_precision,accuracy,precision,recall,f1 = evaluate_model(best_pipeline, X, y, X_test, y_test)\n",
    "\n",
    "    # Log the pipeline and its parameters\n",
    "    mlflow.sklearn.log_model(best_pipeline, \"best_model\")\n",
    "    mlflow.log_params(best_params)\n",
    "    mlflow.log_metric(\"mean_cv_score\", cv_score)\n",
    "    mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "    mlflow.log_metric(\"average_precision\", average_precision)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_metric(\"precision\", precision)\n",
    "    mlflow.log_metric(\"recall\", recall)\n",
    "    mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "    # Save the best model as a joblib file\n",
    "    joblib.dump(best_pipeline, \"best_model.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
