{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6df2981f",
   "metadata": {},
   "source": [
    "# Model registration and versioning with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8937b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score,roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from lightgbm import LGBMClassifier\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fb5b85-206c-4334-b441-a7250cb46730",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/inouyewilliam/Master-Thesis.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"inouyewilliam\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] =\"b185d44c9fe85ded477875ff2ba1b4d229006006\"\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/inouyewilliam/Master-Thesis.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cb390d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, X_test, y_test):\n",
    "    # Evaluate the model using cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Get the model predictions and probabilities\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    avg_precision= average_precision_score(y_test, y_proba)\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    precision= precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "    f1= f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    return cv_score,roc_auc,avg_precision,accuracy,precision,recall,f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "373929a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /inouyewilliam/Master-Thesis.mlflow/api/2.0/mlflow/runs/create\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 15\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "cv_score: 0.7\n",
      "best params: {'model__learning_rate': 0.05287906217433661, 'model__max_depth': 3, 'model__n_estimators': 162, 'model__num_leaves': 13}\n",
      "roc_auc: 0.7984004985459077\n",
      "average_precision: 0.7741817109428892\n",
      "accuracy: 0.7411764705882353\n",
      "precision: 0.7415730337078652\n",
      "recall: 0.7586206896551724\n",
      "f1 score: 0.75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'LgbmModel' already exists. Creating a new version of this model...\n",
      "2023/05/08 23:44:08 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: LgbmModel, version 4\n",
      "Created version '4' of model 'LgbmModel'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Read the preprocess csv file\n",
    "    csv = (\n",
    "        \"C:/Users/willi/Python/Spotify_Project/Data/preprocess_data.csv\"\n",
    "    )\n",
    "    try:\n",
    "        data = pd.read_csv(csv, sep=\",\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.exception(\n",
    "            \"Unable to download training & test CSV. Error: %s\", e\n",
    "        )\n",
    "\n",
    "    # Split the data into training and test sets. (0.8, 0.2) split.\n",
    "    \n",
    "    X = data.drop(\"mood\", axis=1)\n",
    "    y = data[\"mood\"]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Perform Feature Selection to find the best K\n",
    "    \n",
    "    def select_k_best(X, y, estimator, k_values=[5, 10, 15]):\n",
    "        best_k = 0\n",
    "        best_score = float('-inf')\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for k in k_values:\n",
    "            pipeline = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"selector\", SelectKBest(k=k)),\n",
    "                (\"model\", estimator)])\n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "            if scores.mean() > best_score:\n",
    "                best_k = k\n",
    "                best_score = scores.mean()\n",
    "        return best_k\n",
    "    \n",
    "    estimator = LGBMClassifier()\n",
    "    best_k = select_k_best(X_train, y_train, estimator, k_values=[5, 10, 15])\n",
    "    print(f\"Best k: {best_k}\")\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Build a training Pipeline\n",
    "     \n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k=best_k)),\n",
    "            (\"model\", LGBMClassifier())])\n",
    "        \n",
    "        \n",
    "        # Hyperparameter Optimization\n",
    "         \n",
    "        param_distributions = {\n",
    "        \"model__max_depth\": sp_randint(3, 10),\n",
    "        \"model__n_estimators\": sp_randint(50, 200),\n",
    "        \"model__num_leaves\": sp_randint(2, 50),\n",
    "        \"model__learning_rate\": sp_uniform(0.001, 0.1)\n",
    "        }\n",
    "        \n",
    "        \n",
    "        random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=50,\n",
    "                                   cv=5, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Model Evaluation\n",
    "        (cv_score,roc_auc,average_precision,accuracy,precision,recall,f1) = evaluate_model(random_search, X, y, X_test, y_test)\n",
    "\n",
    "        print(\"cv_score: %s\" % cv_score)\n",
    "        print(\"best params: %s\" % random_search.best_params_)\n",
    "        print(\"roc_auc: %s\" % roc_auc)\n",
    "        print(\"average_precision: %s\" % average_precision)\n",
    "        print(\"accuracy: %s\" % accuracy)\n",
    "        print(\"precision: %s\" % precision)\n",
    "        print(\"recall: %s\" % recall)\n",
    "        print(\"f1 score: %s\" % f1)\n",
    "\n",
    "        \n",
    "        mlflow.log_params(random_search.best_params_)\n",
    "        mlflow.log_metric(\"mean_cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"average_precision\", average_precision)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "\n",
    "        # Model registry does not work with file store\n",
    "        if tracking_url_type_store != \"file\":\n",
    "\n",
    "            # Register the model\n",
    "            \n",
    "            mlflow.sklearn.log_model(random_search, \"model\", registered_model_name=\"LgbmModel\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(random_search, \"model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
