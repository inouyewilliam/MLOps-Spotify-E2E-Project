{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6df2981f",
   "metadata": {},
   "source": [
    "# Model registration and versioning with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8937b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, roc_auc_score, precision_score, recall_score,roc_auc_score, average_precision_score\n",
    "from sklearn.model_selection import cross_val_score, RandomizedSearchCV, train_test_split, KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import randint as sp_randint\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6fb5b85-206c-4334-b441-a7250cb46730",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_TRACKING_URI\"] = \"https://dagshub.com/inouyewilliam/Master-Thesis.mlflow\"\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"inouyewilliam\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] =\"b185d44c9fe85ded477875ff2ba1b4d229006006\"\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/inouyewilliam/Master-Thesis.mlflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cb390d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, X_test, y_test):\n",
    "    # Evaluate the model using cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    cv_score = np.mean(cv_scores)\n",
    "    \n",
    "    # Get the model predictions and probabilities\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Calculate the evaluation metrics\n",
    "    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "    avg_precision= average_precision_score(y_test, y_proba)\n",
    "    accuracy= accuracy_score(y_test, y_pred)\n",
    "    precision= precision_score(y_test, y_pred)\n",
    "    recall= recall_score(y_test, y_pred)\n",
    "    f1= f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Return evaluation metrics\n",
    "    return cv_score,roc_auc,avg_precision,accuracy,precision,recall,f1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373929a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Read the preprocess csv file\n",
    "    csv = (\n",
    "            \"C:/Users/willi/Python/Spotify_Project/Data/preprocess_data.csv\"\n",
    "        )\n",
    "    try:\n",
    "            data = pd.read_csv(csv, sep=\",\")\n",
    "            \n",
    "    except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download training & test CSV. Error: %s\", e\n",
    "            )\n",
    "\n",
    "    # Split the data into training and test sets. (0.8, 0.2) split.\n",
    "        \n",
    "    X = data.drop(\"mood\", axis=1)\n",
    "    y = data[\"mood\"]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Perform Feature Selection to find the best K\n",
    "    \n",
    "    def select_k_best(X, y, estimator, k_values=[2, 5, 7, 10, 12, 15]):\n",
    "        best_k = 0\n",
    "        best_score = float('-inf')\n",
    "        best_selector = None\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for k in k_values:\n",
    "            pipeline = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"selector\", SelectKBest(k=k)),\n",
    "                (\"model\", estimator)])\n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "            if scores.mean() > best_score:\n",
    "                best_k = k\n",
    "                best_score = scores.mean()\n",
    "                best_selector = pipeline.named_steps[\"selector\"]\n",
    "                best_selector.fit(X, y)\n",
    "                selected_features = X.columns[best_selector.get_support()]\n",
    "                print(f\"Best k: {best_k}\")\n",
    "                print(f\"Selected features: {list(selected_features)}\")\n",
    "        return best_k\n",
    "    \n",
    "    estimator = LGBMClassifier()\n",
    "    best_k = select_k_best(X_train, y_train, estimator, k_values=[2, 5, 7, 10, 12, 15])\n",
    "    \n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Build a training Pipeline\n",
    "     \n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k= best_k)),\n",
    "            (\"model\", LGBMClassifier())])\n",
    "        \n",
    "        \n",
    "        # Hyperparameter Optimization\n",
    "         \n",
    "        param_distributions = {\n",
    "        \"model__max_depth\": sp_randint(3, 10),\n",
    "        \"model__n_estimators\": sp_randint(50, 200),\n",
    "        \"model__num_leaves\": sp_randint(2, 50),\n",
    "        \"model__learning_rate\": sp_uniform(0.001, 0.1)\n",
    "        }\n",
    "        \n",
    "        \n",
    "        random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=50,\n",
    "                                   cv=5, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Model Evaluation\n",
    "        (cv_score,roc_auc,average_precision,accuracy,precision,recall,f1) = evaluate_model(random_search, X, y, X_test, y_test)\n",
    "\n",
    "        print(\"cv_score: %s\" % cv_score)\n",
    "        print(\"best params: %s\" % random_search.best_params_)\n",
    "        print(\"roc_auc: %s\" % roc_auc)\n",
    "        print(\"average_precision: %s\" % average_precision)\n",
    "        print(\"accuracy: %s\" % accuracy)\n",
    "        print(\"precision: %s\" % precision)\n",
    "        print(\"recall: %s\" % recall)\n",
    "        print(\"f1 score: %s\" % f1)\n",
    "\n",
    "        \n",
    "        mlflow.log_params(random_search.best_params_)\n",
    "        mlflow.log_metric(\"mean_cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"average_precision\", average_precision)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "\n",
    "        # Model registry does not work with file store\n",
    "        if tracking_url_type_store != \"file\":\n",
    "\n",
    "            # Register the model\n",
    "            \n",
    "            mlflow.sklearn.log_model(random_search, \"model\", registered_model_name=\"LgbmModel\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(random_search, \"model\")\n",
    "            #cv_score: 0.6911111111111111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0af6573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 2\n",
      "Selected features: ['danceability', 'energy']\n",
      "Best k: 5\n",
      "Selected features: ['danceability', 'energy', 'loudness', 'duration_ms', 'time_signature']\n",
      "Best k: 10\n",
      "Selected features: ['popularity', 'genres', 'explicit', 'danceability', 'energy', 'loudness', 'mode', 'tempo', 'duration_ms', 'time_signature']\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "cv_score: 0.7050000000000001\n",
      "best params: {'model__bootstrap': True, 'model__criterion': 'gini', 'model__max_depth': 8, 'model__min_samples_leaf': 5, 'model__min_samples_split': 8, 'model__n_estimators': 60}\n",
      "roc_auc: 0.7775030138171927\n",
      "average_precision: 0.7737945715989483\n",
      "accuracy: 0.6972222222222222\n",
      "precision: 0.6857142857142857\n",
      "recall: 0.7700534759358288\n",
      "f1 score: 0.72544080604534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'ExtraTreeModel' already exists. Creating a new version of this model...\n",
      "2023/05/09 17:13:37 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: ExtraTreeModel, version 8\n",
      "Created version '8' of model 'ExtraTreeModel'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Read the preprocess csv file\n",
    "    csv = (\n",
    "            \"C:/Users/willi/Python/Spotify_Project/Data/preprocess_data.csv\"\n",
    "        )\n",
    "    try:\n",
    "            data = pd.read_csv(csv, sep=\",\")\n",
    "            \n",
    "    except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download training & test CSV. Error: %s\", e\n",
    "            )\n",
    "\n",
    "    # Split the data into training and test sets. (0.8, 0.2) split.\n",
    "        \n",
    "    X = data.drop(\"mood\", axis=1)\n",
    "    y = data[\"mood\"]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "    # Perform Feature Selection to find the best K\n",
    "    \n",
    "    def select_k_best(X, y, estimator, k_values=[2, 5, 7, 10, 12, 15]):\n",
    "        best_k = 0\n",
    "        best_score = float('-inf')\n",
    "        best_selector = None\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for k in k_values:\n",
    "            pipeline = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"selector\", SelectKBest(k=k)),\n",
    "                (\"model\", estimator)])\n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "            if scores.mean() > best_score:\n",
    "                best_k = k\n",
    "                best_score = scores.mean()\n",
    "                best_selector = pipeline.named_steps[\"selector\"]\n",
    "                best_selector.fit(X, y)\n",
    "                selected_features = X.columns[best_selector.get_support()]\n",
    "                print(f\"Best k: {best_k}\")\n",
    "                print(f\"Selected features: {list(selected_features)}\")\n",
    "        return best_k\n",
    "    \n",
    "    estimator = ExtraTreesClassifier()\n",
    "    best_k = select_k_best(X_train, y_train, estimator, k_values=[2, 5, 7, 10, 12, 15])\n",
    "    \n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Build a training Pipeline\n",
    "     \n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k= best_k)),\n",
    "            (\"model\", ExtraTreesClassifier())])\n",
    "        \n",
    "        \n",
    "        # Hyperparameter Optimization\n",
    "         \n",
    "        param_distributions = {\n",
    "        \"model__n_estimators\": sp_randint(50, 200),\n",
    "        \"model__max_depth\": sp_randint(3, 10),\n",
    "        \"model__min_samples_split\": sp_randint(2, 10),\n",
    "        \"model__min_samples_leaf\": sp_randint(1, 10),\n",
    "        \"model__bootstrap\": [True, False],\n",
    "        \"model__criterion\": [\"gini\", \"entropy\"]\n",
    "        }\n",
    "        \n",
    "        \n",
    "        random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=50,\n",
    "                                   cv=5, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Model Evaluation\n",
    "        (cv_score,roc_auc,average_precision,accuracy,precision,recall,f1) = evaluate_model(random_search, X, y, X_test, y_test)\n",
    "\n",
    "        print(\"cv_score: %s\" % cv_score)\n",
    "        print(\"best params: %s\" % random_search.best_params_)\n",
    "        print(\"roc_auc: %s\" % roc_auc)\n",
    "        print(\"average_precision: %s\" % average_precision)\n",
    "        print(\"accuracy: %s\" % accuracy)\n",
    "        print(\"precision: %s\" % precision)\n",
    "        print(\"recall: %s\" % recall)\n",
    "        print(\"f1 score: %s\" % f1)\n",
    "\n",
    "        \n",
    "        mlflow.log_params(random_search.best_params_)\n",
    "        mlflow.log_metric(\"mean_cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"average_precision\", average_precision)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "\n",
    "        # Model registry does not work with file store\n",
    "        if tracking_url_type_store != \"file\":\n",
    "\n",
    "            # Register the model\n",
    "            \n",
    "            mlflow.sklearn.log_model(random_search, \"model\", registered_model_name=\"ExtraTreeModel\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(random_search, \"model\")\n",
    "            #cv_score: 0.7033333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6ad8d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 2\n",
      "Selected features: ['danceability', 'energy']\n",
      "Best k: 5\n",
      "Selected features: ['danceability', 'energy', 'loudness', 'duration_ms', 'time_signature']\n",
      "Best k: 7\n",
      "Selected features: ['explicit', 'danceability', 'energy', 'loudness', 'tempo', 'duration_ms', 'time_signature']\n",
      "Best k: 10\n",
      "Selected features: ['popularity', 'genres', 'explicit', 'danceability', 'energy', 'loudness', 'mode', 'tempo', 'duration_ms', 'time_signature']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=4, connect=5, read=4, redirect=5, status=5)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /inouyewilliam/Master-Thesis.mlflow/api/2.0/mlflow/runs/create\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "cv_score: 0.6994444444444445\n",
      "best params: {'model__colsample_bytree': 0.9678174971104738, 'model__learning_rate': 0.07953406511139437, 'model__max_depth': 6, 'model__n_estimators': 161, 'model__reg_lambda': 0.2014715428660321, 'model__subsample': 0.8317508845540279}\n",
      "roc_auc: 0.7941949244227382\n",
      "average_precision: 0.7870229633665965\n",
      "accuracy: 0.7083333333333334\n",
      "precision: 0.7091836734693877\n",
      "recall: 0.7433155080213903\n",
      "f1 score: 0.7258485639686684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGBModel' already exists. Creating a new version of this model...\n",
      "2023/05/09 17:30:19 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: XGBModel, version 5\n",
      "Created version '5' of model 'XGBModel'.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "    # Read the preprocess csv file\n",
    "    csv = (\n",
    "            \"C:/Users/willi/Python/Spotify_Project/Data/preprocess_data.csv\"\n",
    "        )\n",
    "    try:\n",
    "            data = pd.read_csv(csv, sep=\",\")\n",
    "            \n",
    "    except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download training & test CSV. Error: %s\", e\n",
    "            )\n",
    "\n",
    "    # Split the data into training and test sets. (0.8, 0.2) split.\n",
    "        \n",
    "    X = data.drop(\"mood\", axis=1)\n",
    "    y = data[\"mood\"]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "       \n",
    "    # Perform Feature Selection to find the best K\n",
    "    \n",
    "    def select_k_best(X, y, estimator, k_values=[2, 5, 7, 10, 12, 15]):\n",
    "        best_k = 0\n",
    "        best_score = float('-inf')\n",
    "        best_selector = None\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for k in k_values:\n",
    "            pipeline = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"selector\", SelectKBest(k=k)),\n",
    "                (\"model\", estimator)])\n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "            if scores.mean() > best_score:\n",
    "                best_k = k\n",
    "                best_score = scores.mean()\n",
    "                best_selector = pipeline.named_steps[\"selector\"]\n",
    "                best_selector.fit(X, y)\n",
    "                selected_features = X.columns[best_selector.get_support()]\n",
    "                print(f\"Best k: {best_k}\")\n",
    "                print(f\"Selected features: {list(selected_features)}\")\n",
    "        return best_k\n",
    "    \n",
    "    estimator = XGBClassifier()\n",
    "    best_k = select_k_best(X_train, y_train, estimator, k_values=[2, 5, 7, 10, 12, 15])\n",
    "    \n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Build a training Pipeline\n",
    "     \n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k= best_k)),\n",
    "            (\"model\", XGBClassifier())])\n",
    "        \n",
    "        \n",
    "        # Hyperparameter Optimization\n",
    "         \n",
    "        param_distributions = {\n",
    "        \"model__max_depth\": sp_randint(3, 10),\n",
    "        \"model__n_estimators\": sp_randint(50, 200),\n",
    "        \"model__learning_rate\": sp_uniform(0.001, 0.1),\n",
    "        \"model__subsample\": sp_uniform(0.5, 0.5),\n",
    "        \"model__colsample_bytree\": sp_uniform(0.5, 0.5),\n",
    "        \"model__reg_lambda\": sp_uniform(0.1, 1)\n",
    "        }\n",
    "        \n",
    "        \n",
    "        random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=50,\n",
    "                                   cv=5, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Model Evaluation\n",
    "        (cv_score,roc_auc,average_precision,accuracy,precision,recall,f1) = evaluate_model(random_search, X, y, X_test, y_test)\n",
    "\n",
    "        print(\"cv_score: %s\" % cv_score)\n",
    "        print(\"best params: %s\" % random_search.best_params_)\n",
    "        print(\"roc_auc: %s\" % roc_auc)\n",
    "        print(\"average_precision: %s\" % average_precision)\n",
    "        print(\"accuracy: %s\" % accuracy)\n",
    "        print(\"precision: %s\" % precision)\n",
    "        print(\"recall: %s\" % recall)\n",
    "        print(\"f1 score: %s\" % f1)\n",
    "\n",
    "        \n",
    "        mlflow.log_params(random_search.best_params_)\n",
    "        mlflow.log_metric(\"mean_cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"average_precision\", average_precision)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "\n",
    "        # Model registry does not work with file store\n",
    "        if tracking_url_type_store != \"file\":\n",
    "\n",
    "            # Register the model\n",
    "            \n",
    "            mlflow.sklearn.log_model(random_search, \"model\", registered_model_name=\"XGBModel\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(random_search, \"model\")\n",
    "            #cv_score: 0.6994444444444445"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8e567",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Read the preprocess csv file\n",
    "    csv = (\n",
    "            \"C:/Users/willi/Python/Spotify_Project/Data/preprocess_data.csv\"\n",
    "        )\n",
    "    try:\n",
    "            data = pd.read_csv(csv, sep=\",\")\n",
    "            \n",
    "    except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download training & test CSV. Error: %s\", e\n",
    "            )\n",
    "\n",
    "    # Split the data into training and test sets. (0.8, 0.2) split.\n",
    "        \n",
    "    X = data.drop(\"mood\", axis=1)\n",
    "    y = data[\"mood\"]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Perform Feature Selection to find the best K\n",
    "    \n",
    "    def select_k_best(X, y, estimator, k_values=[2, 5, 7, 10, 12, 15]):\n",
    "        best_k = 0\n",
    "        best_score = float('-inf')\n",
    "        best_selector = None\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for k in k_values:\n",
    "            pipeline = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"selector\", SelectKBest(k=k)),\n",
    "                (\"model\", estimator)])\n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "            if scores.mean() > best_score:\n",
    "                best_k = k\n",
    "                best_score = scores.mean()\n",
    "                best_selector = pipeline.named_steps[\"selector\"]\n",
    "                best_selector.fit(X, y)\n",
    "                selected_features = X.columns[best_selector.get_support()]\n",
    "                print(f\"Best k: {best_k}\")\n",
    "                print(f\"Selected features: {list(selected_features)}\")\n",
    "        return best_k\n",
    "    \n",
    "    estimator = RandomForestClassifier()\n",
    "    best_k = select_k_best(X_train, y_train, estimator, k_values=[2, 5, 7, 10, 12, 15])\n",
    "    \n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Build a training Pipeline\n",
    "     \n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k= best_k)),\n",
    "            (\"model\", RandomForestClassifier())])\n",
    "        \n",
    "        \n",
    "        # Hyperparameter Optimization\n",
    "         \n",
    "        param_distributions = {\n",
    "        \"model__n_estimators\": sp_randint(50, 200),\n",
    "        \"model__max_depth\": sp_randint(3, 10),\n",
    "        \"model__min_samples_split\": sp_randint(2, 20),\n",
    "        \"model__min_samples_leaf\": sp_randint(1, 10),\n",
    "        }\n",
    "\n",
    "        \n",
    "        \n",
    "        random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=50,\n",
    "                                   cv=5, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Model Evaluation\n",
    "        (cv_score,roc_auc,average_precision,accuracy,precision,recall,f1) = evaluate_model(random_search, X, y, X_test, y_test)\n",
    "\n",
    "        print(\"cv_score: %s\" % cv_score)\n",
    "        print(\"best params: %s\" % random_search.best_params_)\n",
    "        print(\"roc_auc: %s\" % roc_auc)\n",
    "        print(\"average_precision: %s\" % average_precision)\n",
    "        print(\"accuracy: %s\" % accuracy)\n",
    "        print(\"precision: %s\" % precision)\n",
    "        print(\"recall: %s\" % recall)\n",
    "        print(\"f1 score: %s\" % f1)\n",
    "\n",
    "        \n",
    "        mlflow.log_params(random_search.best_params_)\n",
    "        mlflow.log_metric(\"mean_cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"average_precision\", average_precision)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "\n",
    "        # Model registry does not work with file store\n",
    "        if tracking_url_type_store != \"file\":\n",
    "\n",
    "            # Register the model\n",
    "            \n",
    "            mlflow.sklearn.log_model(random_search, \"model\", registered_model_name=\"RandomForestModel\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(random_search, \"model\")\n",
    "            #cv_score: 0.6955555555555556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411dcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # Read the preprocess csv file\n",
    "    csv = (\n",
    "            \"C:/Users/willi/Python/Spotify_Project/Data/preprocess_data.csv\"\n",
    "        )\n",
    "    try:\n",
    "            data = pd.read_csv(csv, sep=\",\")\n",
    "            \n",
    "    except Exception as e:\n",
    "            logger.exception(\n",
    "                \"Unable to download training & test CSV. Error: %s\", e\n",
    "            )\n",
    "\n",
    "    # Split the data into training and test sets. (0.8, 0.2) split.\n",
    "        \n",
    "    X = data.drop(\"mood\", axis=1)\n",
    "    y = data[\"mood\"]\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Perform Feature Selection to find the best K\n",
    "    \n",
    "    def select_k_best(X, y, estimator, k_values=[2, 5, 7, 10, 12, 15]):\n",
    "        best_k = 0\n",
    "        best_score = float('-inf')\n",
    "        best_selector = None\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        for k in k_values:\n",
    "            pipeline = Pipeline([\n",
    "                (\"scaler\", StandardScaler()),\n",
    "                (\"selector\", SelectKBest(k=k)),\n",
    "                (\"model\", estimator)])\n",
    "            scores = cross_val_score(pipeline, X, y, cv=cv)\n",
    "            if scores.mean() > best_score:\n",
    "                best_k = k\n",
    "                best_score = scores.mean()\n",
    "                best_selector = pipeline.named_steps[\"selector\"]\n",
    "                best_selector.fit(X, y)\n",
    "                selected_features = X.columns[best_selector.get_support()]\n",
    "                print(f\"Best k: {best_k}\")\n",
    "                print(f\"Selected features: {list(selected_features)}\")\n",
    "        return best_k\n",
    "    \n",
    "    estimator = GradientBoostingClassifier()\n",
    "    best_k = select_k_best(X_train, y_train, estimator, k_values=[2, 5, 7, 10, 12, 15])\n",
    "    \n",
    "\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Build a training Pipeline\n",
    "     \n",
    "        pipeline = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"selector\", SelectKBest(f_classif, k = best_k)),\n",
    "            (\"model\", GradientBoostingClassifier())])\n",
    "        \n",
    "        \n",
    "        # Hyperparameter Optimization\n",
    "         \n",
    "        param_distributions = {\n",
    "        \"model__n_estimators\": sp_randint(50, 200),\n",
    "        \"model__max_depth\": sp_randint(3, 10),\n",
    "        \"model__min_samples_split\": sp_randint(2, 20),\n",
    "        \"model__min_samples_leaf\": sp_randint(1, 10),\n",
    "        \"model__learning_rate\": sp_uniform(0.001, 0.1)\n",
    "        }\n",
    "\n",
    "        \n",
    "        \n",
    "        random_search = RandomizedSearchCV(pipeline, param_distributions=param_distributions, n_iter=50,\n",
    "                                   cv=5, n_jobs=-1, verbose=2)\n",
    "        \n",
    "        random_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Model Evaluation\n",
    "        (cv_score,roc_auc,average_precision,accuracy,precision,recall,f1) = evaluate_model(random_search, X, y, X_test, y_test)\n",
    "\n",
    "        print(\"cv_score: %s\" % cv_score)\n",
    "        print(\"best params: %s\" % random_search.best_params_)\n",
    "        print(\"roc_auc: %s\" % roc_auc)\n",
    "        print(\"average_precision: %s\" % average_precision)\n",
    "        print(\"accuracy: %s\" % accuracy)\n",
    "        print(\"precision: %s\" % precision)\n",
    "        print(\"recall: %s\" % recall)\n",
    "        print(\"f1 score: %s\" % f1)\n",
    "\n",
    "        \n",
    "        mlflow.log_params(random_search.best_params_)\n",
    "        mlflow.log_metric(\"mean_cv_score\", cv_score)\n",
    "        mlflow.log_metric(\"roc_auc\", roc_auc)\n",
    "        mlflow.log_metric(\"average_precision\", average_precision)\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1 score\", f1)\n",
    "\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "\n",
    "\n",
    "        # Model registry does not work with file store\n",
    "        if tracking_url_type_store != \"file\":\n",
    "\n",
    "            # Register the model\n",
    "            \n",
    "            mlflow.sklearn.log_model(random_search, \"model\", registered_model_name=\"GradientBoostingModel\")\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(random_search, \"model\")\n",
    "            #cv_score: 0.6955555555555556"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
